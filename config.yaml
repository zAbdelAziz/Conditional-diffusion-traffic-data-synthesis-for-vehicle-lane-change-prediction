runner:
  name: trainer-test-1
  seed: 42
  dataset:
    train: ngsim
    test: ngsim
    analyze: false
    online_synth: false
    synth_samples: 1000
  train:
    synth: true
    downstream: true
  model:
    diffusion: GaussianDiffusion
    synth: UNETDenoiser
    downstream: BiGRUClassifier
  dirs:
    root_datasets: datasets-files
    root_models: models-checkpoints
    raw_datasets: ${runner.dirs.root_datasets}/raw
    refactored_datasets: ${runner.dirs.root_datasets}/refactored
    synth_datasets: ${runner.dirs.root_datasets}/synth
    downstream_model: ${runner.dirs.root_models}/downstream
    synth_model: ${runner.dirs.root_models}/synth

datasets:
  ngsim:
    clsName: NgsimDataset
    columns:
      - Vehicle_ID
      - Frame_ID
      - Local_X
      - Local_Y
      - Lane_ID
      - Preceding
      - Following
    subsets:
      locations:
        - i-80
    preprocessing:
      dt: 0.1
      balance_classes: true
      smoothing:
        sg_window: 41
        sg_polyorder: 3
      sequence:
        length: 50
        stride: 30
        horizon: 30
        min_track_len: 120
      labeling:
        # horizon | boundary
        method: boundary
        # for boundary [segments] in radians
        theta_start: 0.02
        theta_end: 0.02
        # for boundary [segments]
        consec: 3
      vision_threshold:
        tol: 0.001
        pad: 1.05
        quantile: 0.999
        max_frames: 50000

models:
  GaussianDiffusion:
    clsName: GaussianDiffusionModel
    hyperparams:
      T: 175
      beta_schedule: cosine
  UNETDenoiser:
    clsName: UNETDenoiserModel
    hyperparams:
      data_dim: 14
      base_channels: 128
      cond_dim: 256
      dropout: 0.1
      attn_heads: 8
      use_attn_mid: true
      use_attn_low: true
      num_classes: 3
      cfg_drop_prob: 0.15
  TransformerDenoiser:
    clsName: TransformerDenoiserModel
    hyperparams:
      name: test

  BiGRUClassifier:
    clsName: BiGRUClassifierModel
    hyperparams:
      name: test
  TransformerBiGRUClassifier:
    clsName: TransformerBiGRUClassifierModel
    hyperparams:
      name: test
  xLSTMClassifier:
    clsName: xLSTMClassifierModel
    hyperparams:
      name: test

trainers:
  diffSynth:
    clsName: SynthTrainer
    epochs: 2
    batch_size: 64
    clip_grad: true
    standardize: true
    balance_labels: true
    y_conditional: true
    compile: false
    split:
      mode: group
      train: 0.70
      valid: 0.15
      test: 0.15
    loss:
      clsName: MSELoss
      snr_gamma: 5.0
      snr_eps: 1e-12
    optimizer:
      clsName: AdamW
      params:
        lr: 0.001
        weight_decay: 0.01
    scheduler:
      clsName: CosineAnnealingLR
      step_per: epoch
      params:
        T_max: ${trainers.diffSynth.epochs}
        eta_min: 0.00005
    checkpoint:
      enabled: true
      metric: "valid/loss"
      mode: "min"
    sampling:
      steps: ${models.${runner.model.diffusion}.hyperparams.T}
      method: ddpm
      eta: 0.0
  downstream:
    clsName: DownstreamTrainer
    epochs: 20
    batch_size: 64
    clip_grad: true
    standardize: true
    balance_labels: true
    split:
      mode: group
      train: 0.70
      valid: 0.15
      test: 0.15
    loss:
      clsName: CrossEntropyLoss
    optimizer:
      clsName: AdamW
      params:
        lr: 0.0007
        weight_decay: 5e-3
    scheduler:
      clsName: CosineAnnealingLR
      step_per: epoch
      params:
        T_max: ${trainers.downstream.epochs}
        eta_min: 1e-5
    checkpoint:
      enabled: true
      metric: "valid/acc"
      mode: "max"
      every_n_epochs: 1

logger:
  path: logs
  lock: false
  level: debug
  console: true
  console_flush: false
  bufferSize: 100
  buf_threshold: 0

wandb:
  enabled: true
  project: thesis
  entity: null
  tags:
    - ${runner.dataset.train}
    - ${runner.dataset.test}
    - ${runner.model.downstream}
  notes: ""
  # Log Artifacts
  log_model: false
  watch:
    enabled: false
    # "gradients" | "parameters" | "all"
    log: "gradients"
    log_freq: 100
  log_confusion: true